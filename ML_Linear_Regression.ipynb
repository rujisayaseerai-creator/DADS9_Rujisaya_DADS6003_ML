{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vejWUMNQ7Ig",
        "outputId": "f09c11d9-c7eb-4625-a5f6-8fc567c34150"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scikit-learn Accuracy: 0.8333333333333334\n",
            "Batch Gradient Descent Accuracy: 0.8333333333333334\n",
            "Stochastic Gradient Descent Accuracy: 0.8333333333333334\n",
            "เทสๆAccuracy each fold: [0.78571429 0.76923077]\n",
            "เทสๆAccuracy avg: 0.7774725274725275\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# 1) Dataset จากอาจารย์\n",
        "# =====================================================\n",
        "\n",
        "data = [\n",
        "[1,0.8,0.83,0.66,1.9,1.1,1],\n",
        "[1,0.9,0.36,0.32,1.4,0.74,0.99],\n",
        "[0,0.8,0.88,0.7,0.8,0.18,0.98],\n",
        "[0,1,0.87,0.87,0.7,1.05,0.99],\n",
        "[1,0.9,0.75,0.68,1.3,0.52,0.98],\n",
        "[0,1,0.65,0.65,0.6,0.52,0.98],\n",
        "[1,0.95,0.97,0.92,1,1.23,0.99],\n",
        "[0,0.95,0.87,0.83,1.9,1.35,1.02],\n",
        "[0,1,0.45,0.45,0.8,0.32,1],\n",
        "[0,0.95,0.36,0.34,0.5,0,1.04],\n",
        "[0,0.85,0.39,0.33,0.7,0.28,0.99],\n",
        "[0,0.7,0.76,0.53,1.2,0.15,0.98],\n",
        "[0,0.8,0.46,0.37,0.4,0.38,1.01],\n",
        "[0,0.2,0.39,0.08,0.8,0.11,0.99],\n",
        "[0,1,0.9,0.9,1.1,1.04,0.99],\n",
        "[1,1,0.84,0.84,1.9,2.06,1.02],\n",
        "[0,0.65,0.42,0.27,0.5,0.11,1.01],\n",
        "[0,1,0.75,0.75,1,1.32,1],\n",
        "[0,0.5,0.44,0.22,0.6,0.11,0.99],\n",
        "[1,1,0.63,0.63,1.1,1.07,0.99],\n",
        "[0,1,0.33,0.33,0.4,0.18,1.01],\n",
        "[0,0.9,0.93,0.84,0.6,1.59,1.02],\n",
        "[1,1,0.58,0.58,1,0.53,1],\n",
        "[0,0.95,0.32,0.3,1.6,0.89,0.99],\n",
        "[1,1,0.6,0.6,1.7,0.96,0.99],\n",
        "[1,1,0.69,0.69,0.9,0.4,0.99],\n",
        "[0,1,0.73,0.73,0.7,0.4,0.99]\n",
        "]\n",
        "\n",
        "columns = [\"REMISS\",\"CELL\",\"SMEAR\",\"INFIL\",\"LI\",\"BLAST\",\"TEMP\"]\n",
        "df = pd.DataFrame(data, columns=columns)\n",
        "\n",
        "X = df.drop(\"REMISS\", axis=1).values\n",
        "y = df[\"REMISS\"].values\n",
        "\n",
        "# =====================================================\n",
        "# 2) Train/Test Split (80/20)\n",
        "# =====================================================\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=50\n",
        ")\n",
        "\n",
        "# =====================================================\n",
        "# 3) Feature Scaling\n",
        "# =====================================================\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# =====================================================\n",
        "# 4) Logistic Regression using scikit-learn\n",
        "# =====================================================\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_sklearn = model.predict(X_test)\n",
        "acc_sklearn = accuracy_score(y_test, y_pred_sklearn)\n",
        "\n",
        "print(\"Scikit-learn Accuracy:\", acc_sklearn)\n",
        "\n",
        "# =====================================================\n",
        "# 5) Batch Gradient Descent (From Scratch) ปรับ learning rate กับ epochs ไปเรื่อยๆจนได้ตัวเลขที่ใกล้1 แบบsignificant\n",
        "# =====================================================\n",
        "\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def batch_gradient_descent(X, y, lr=0.01, epochs=10000):\n",
        "    m, n = X.shape\n",
        "    w = np.zeros(n)\n",
        "    b = 0\n",
        "\n",
        "    for _ in range(epochs):\n",
        "        z = np.dot(X, w) + b\n",
        "        y_hat = sigmoid(z)\n",
        "\n",
        "        dw = (1/m) * np.dot(X.T, (y_hat - y))\n",
        "        db = (1/m) * np.sum(y_hat - y)\n",
        "\n",
        "        w -= lr * dw\n",
        "        b -= lr * db\n",
        "\n",
        "    return w, b\n",
        "\n",
        "w_batch, b_batch = batch_gradient_descent(X_train, y_train)\n",
        "\n",
        "z_test = np.dot(X_test, w_batch) + b_batch\n",
        "y_pred_batch = (sigmoid(z_test) >= 0.5).astype(int)\n",
        "\n",
        "acc_batch = accuracy_score(y_test, y_pred_batch)\n",
        "\n",
        "print(\"Batch Gradient Descent Accuracy:\", acc_batch)\n",
        "\n",
        "# =====================================================\n",
        "# 6) Stochastic Gradient Descent (From Scratch) ปรับ learning rate กับ epochs ไปเรื่อยๆจนได้ตัวเลขที่ใกล้1 แบบsignificant\n",
        "# =====================================================\n",
        "\n",
        "def stochastic_gradient_descent(X, y, lr=0.01, epochs=10000):\n",
        "    m, n = X.shape\n",
        "    w = np.zeros(n)\n",
        "    b = 0\n",
        "\n",
        "    for _ in range(epochs):\n",
        "        for i in range(m):\n",
        "            xi = X[i]\n",
        "            yi = y[i]\n",
        "\n",
        "            z = np.dot(xi, w) + b\n",
        "            y_hat = sigmoid(z)\n",
        "\n",
        "            error = y_hat - yi\n",
        "\n",
        "            w -= lr * error * xi\n",
        "            b -= lr * error\n",
        "\n",
        "    return w, b\n",
        "\n",
        "w_sgd, b_sgd = stochastic_gradient_descent(X_train, y_train)\n",
        "\n",
        "z_test_sgd = np.dot(X_test, w_sgd) + b_sgd\n",
        "y_pred_sgd = (sigmoid(z_test_sgd) >= 0.5).astype(int)\n",
        "\n",
        "acc_sgd = accuracy_score(y_test, y_pred_sgd)\n",
        "\n",
        "print(\"Stochastic Gradient Descent Accuracy:\", acc_sgd)\n",
        "\n",
        "\n",
        "##-----ลองใช้ polynomaial_cross validation---ลองปรับ cvจาก5 เพิ่มลด จนรู้ว่าข้อมูลที่มีน้อย ถ้าแบ่งfoldเยอะmodelมันจะทำpatternทำให้จริงๆแล้วไม่ได้แม่น แล้วค่าที่ได้จะเหวี่ยง ไม่นิ่ง-----##\n",
        "model = make_pipeline(\n",
        "    PolynomialFeatures(degree=1, include_bias=False),\n",
        "    StandardScaler(),\n",
        "    LogisticRegression(max_iter=10000)\n",
        ")\n",
        "\n",
        "scores = cross_val_score(model, X, y, cv=2)\n",
        "\n",
        "print(\"เทสๆAccuracy each fold:\", scores)\n",
        "print(\"เทสๆAccuracy avg:\", np.mean(scores))"
      ]
    }
  ]
}